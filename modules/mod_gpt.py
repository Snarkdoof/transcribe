import json
import re
import copy
import os
import math

try:
    import openai
    CANRUN = True
    if os.path.exists(".openai_key"):
        with open(".openai_key", "r") as f:
            openai.api_key = f.read().strip()
    else:
        openai.api_key = os.getenv("OPENAI_API_KEY")
except:
    print("Can't run whisper in this environment")
    CANRUN = False



ccmodule = {
    "description": "Use GPT to alter text",
    "depends": [],
    "provides": [],
    "inputs": {
        "src": "Subtitle file to alter (json)",
        "reprocess": "Force reprocessing, default False", 
        "prompt": "The prompt to run (default is clean up)",
        "dst": "Destination file, optional",
        "model": "gpt-4",
        "max_tokens": 8000
    },
    "outputs": {
        "dst": "Output file"
    },
    "defaults": {
        "priority": 50,  # Normal
        "runOn": "success"
    },
    "status": {
        "progress": "Progress 0-100%",
        "state": "Current state of processing"
    }
}


class TextFixer:

    SYSTEM_CONTEXT = "You are a grammar and spelling fixing master, outputting the necessary differences to easily fix the source data."
    STANDARD_DEFAULT_PROMPT = """Fix spelling in the following set of subtitles but
don't change the order of words or meaning. Allow sentences to
span multiple lines. Avoid printing lines without corrections, and keep
all line breaks and line numbers unchanged. Write in Norwegian."""

    VERBATIM_DEFAULT_PROMPT = """Fix spelling in the following set of subtitles. Only fix spelling, change as few words as possible. Write in Norwegian."""
    COMPRESS_DEFAULT_PROMPT = """Correct and compress the following subtitles while maintaining the oral feeling and word ordering when possible. The output should keep all meaning and style, but superfluous words should be removed when possible. Write in Norwegian."""

    DEFAULT_PROMPT = VERBATIM_DEFAULT_PROMPT

    def __init__(self, cc, model="gpt-3.5-turbo", max_tokens=4000):

        self.cc = cc
        self.model = model
        self.max_tokens = max_tokens
        self.cache = {}

        self.cachefile = "/tmp/mod_gpt.cache"
        if os.path.exists(self.cachefile):
            try:
                with open(self.cachefile, "r") as f:
                    self.cache = json.load(f)
            except:
                cc.log.exception("Failed to load cache file '{}'".format(self.cachefile))

    def __del__(self):
        with open(self.cachefile, "w") as f:
            json.dump(self.cache, f)

    def read_file(self, filename):
        if filename.lower().endswith(".json"):
            with open(filename, "r") as f:
                data = json.load(f)
        else:
            raise SystemExit("Don't support VTT for now")

        # Is this generated by whisper?
        if "segments" in data:
            data = data["segments"]


        # We merge segments, we want fuller lines if possible
        from mod_reformat2 import merge_segments
        segments = merge_segments(data)

        # We create numbered text lines to save some space
        lines = []
        for idx, item in enumerate(segments):
            lines.append("{}: {}".format(idx, item["text"].strip().replace("\n", " ")))

        # We now have lots of lines, process it
        return lines, segments

    def process_lines(self, lines, prompt=None):
        if not prompt:
            prompt = self.DEFAULT_PROMPT
        # We guess that the number of tokens for in and output must be roughly the same
        FUDGE = 1000  # Keep some extra "room" for the reply
        start = 0
        end = 10
        ret = []
        while start < len(lines):

            # Split into likely ok lenghts
            avg_token_length = 2.9  # Pure guesswork I think

            if end < len(lines):
                if len("\n".join(lines[start:end])) / avg_token_length < ((self.max_tokens / 2) - FUDGE):
                    end += 1
                    continue

            # We're either at the end or have enough for now
            self.cc.log.debug("Processing {}:{}".format(start, end))

            txt = prompt
            msgs = [
                        {"role": "system", "content": self.SYSTEM_CONTEXT},
                        {"role": "user", "content": txt},
                        {"role": "assistant", "content": "Ok, I will fix and output changed lines."},
                        {"role": "user", "content": "\n".join(lines[start:end])}
                    ]

            c_key = json.dumps(msgs)
            if c_key not in self.cache:
                response = openai.ChatCompletion.create(
                      model=self.model,
                      messages=msgs,
                      max_tokens=int(self.max_tokens * 0.3)
                    )
                self.cache[c_key] = response["choices"][0]['message']['content']

            print("-----------------------\n{}\n\n".format(msgs), self.cache[c_key])
            print("Length of query:", len(c_key))
            ret.extend(self.cache[c_key].split("\n"))

            with open(self.cachefile, "w") as f:
                json.dump(self.cache, f)

            self.cc.status["progress"] = int(100 * end / len(lines))
            start = end

        return ret

    def recreate_subfile(self, data, lines):
        """
        data is the orginial loaded data, lines is the processed and processed lines
        """
        # First we make the lines into a map split by the int
        pattern = r'^(\d+): (.*)$'
        altered = {}
        for line in lines:
            match = re.match(pattern, line)
            if match:
                number = int(match.group(1))
                text = match.group(2)
                altered[number] = text
            else:
                print("BAD LINE '{}'".format(line))

        # Merge if altered
        merged_data = copy.copy(data)
        for idx, item in enumerate(merged_data):
            if idx in altered:
                if item["text"].strip() == altered[idx].strip():
                    continue  # GPT doesn't always follow our instructions

                print("OLD: {}\nNEW: {}".format(item["text"], altered[idx]))
                item["text_whisper"] = item["text"]
                item["text"] = altered[idx]
        return merged_data

def process_task(cc, task, stop_event):

    args = task["args"]

    src = args["src"]
    dst = args.get("dst", None)
    if not dst:
        p, e = os.path.splitext(src)
        dst = p + "_gpt" + e
    reprocess = args.get("reprocess", False)
    prompt = args.get("prompt", None)
    model = args.get("model", "gpt-3.5-turbo")
    max_tokens = args.get("max_tokens", 4000)
    key = args.get("openai_api_key", None)
    if key:
        openai.api_key = key

    fixer = TextFixer(cc, model, max_tokens)

    if os.path.exists(dst) and not reprocess:
        cc.log.info("Cached result in {}".format(dst))
        return 100, {"dst": dst}

    lines, data = fixer.read_file(src)
    new_lines = fixer.process_lines(lines, prompt)
    new_subs = fixer.recreate_subfile(data, new_lines)

    # Write the new ones
    if dst.lower().endswith(".json"):
        with open(dst, "w") as f:
            json.dump(new_subs, f, indent=" ")
    else:
        # Try to merge stuff
        from mod_reformat2 import split_segments, balance
        max_chars = 40
        new_segments = split_segments(new_subs, math.floor(max_chars * 1.8))
        new_subs = [{"start": s["start"], "end": s["end"], "text": balance(s["text"], max_chars)} for s in new_segments]

        raise Exception("CAN'T WRITE THIS TO VTT, segments are merged and way too long")
        from mod_reformat2 import write_vtt
        write_vtt(new_subs, dst)
    return 100, {"dst": dst}
